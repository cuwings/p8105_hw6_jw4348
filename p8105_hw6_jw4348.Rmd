---
title: "p8105_hw6_jw4348"
author: "Jingyu Wang"
output: github_document
date: "2023-12-01"
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

In the data cleaning code below we create a `city_state` variable, change `victim_age` to numeric, modifiy victim_race to have categories white and non-white, with white as the reference category, and create a `resolution` variable indicating whether the homicide is solved. Lastly, we filtered out the following cities: Tulsa, AL; Dallas, TX; Phoenix, AZ; and Kansas City, MO; and we retained only the variables `city_state`, `resolution`, `victim_age`, `victim_sex`, and `victim_race`.

```{r q1_data_cleaning}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```

Next we fit a logistic regression model using only data from Baltimore, MD. We model `resolved` as the outcome and `victim_age`, `victim_sex`, and `victim_race` as predictors. We save the output as `baltimore_glm` so that we can apply `broom::tidy` to this object and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims.

```{r q1_glm_baltimore}
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

Below, by incorporating `nest()`, `map()`, and `unnest()` into the preceding Baltimore-specific code, we fit a model for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. We show the first 5 rows of the resulting dataframe of model results.

```{r q1_glm_all_cities}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

```{r q1_plot}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Problem 2

### First, I will download the Central Park weather data.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

### Then I will clean the dataset.

```{r}
centralpark_df = 
  weather_df |> 
  drop_na(prcp, tmax, tmin) |> 
  select(id, tmax, tmin, prcp)

centralpark_df
```

### Then I will use 5000 bootstrap samples and produce estimates of `R square` quantities. 

```{r}
boot_sample = function(df) {
  
  sample_frac(df, replace = TRUE)
  
}

boot_results_rsquare = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(centralpark_df)),
    models = map(strap_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::glance)
  ) |> 
  select(strap_number, results) |> 
  unnest(results)
```

### Then I will Plot the distribution of `rsquare`.
```{r}
boot_results_rsquare |> 
  ggplot(aes(x = r.squared)) +
  geom_density()
```

- The plot is a left-skewed of R-squared values from 5000 bootstrap samples, centered around 0.913, indicating a model fit that explains about 91.3% of the variance in the maximum temperature, based on minimum temperature and precipitation. The longer tail towards lower values indicates some samples with less explained variance, possibly due to variability or outliers in those samples.

### Then I will construct `95% confidence interval` of rsquare

```{r}
boot_results_rsquare |> 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  )
```

### Next I will use 5000 bootstrap samples and produce estimates of `log(beta1*beta2)` quantities. 

```{r}
boot_results_logbeta = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(centralpark_df)),
    models = map(strap_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy)
  ) |> 
  select(strap_number, results) |> 
  unnest(results) |> 
  select(strap_number, term, estimate) |> 
  pivot_wider(
    names_from = term, 
    values_from = estimate) |> 
  rename(beta1 = tmin, beta2 = prcp) |>
  mutate(log_b1b2 = log(beta1 * beta2)) 
```
- Because there are a lot of negative values of variable `prec` resulting in **NaN** value of `log(beta1 * beta2)`.

### Then I will Plot the distribution of `log(beta1*beta2)`.

```{r}
boot_results_logbeta |> 
  ggplot(aes(x = log_b1b2)) +
  geom_density()
```

- The plot is a left-skewed of R-squared values from 5000 bootstrap samples, centered around -5.5. This skew suggests outliers with small products of β1 and β2, influencing the shape of the distribution.

### Then I will construct `95% confidence interval` of log(beta1*beta2).

```{r}
boot_results_logbeta |> 
  filter(log_b1b2 != "NaN") |>
  summarize(
    ci_lower = quantile(log_b1b2, 0.025),
    ci_upper = quantile(log_b1b2, 0.975)
  )
```

- Because we can't compute the 95%CI for the estimates of `NaN` values, therefore we only produce the 95% confidence interval of `log(beta1*beta2)` only restricted **non-NaN** values.

## Problem 3

### First I will load and clean the data for regression analysis, convert some variables from numeric to factor.

```{r}
birthweight_df = 
  read_csv("data/birthweight.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) 

birthweight_df
```

### Then I will check is there missing data in `birthweight_df`.

```{r}
sapply(birthweight_df, function(x) sum(is.na(x)))
```
- There is no any missing values in **birthweight_df**.

### Then I will choose the variables I think might be factors of birthweight then fit in the model.

- In my model, I will include `blength`, `malform`, `ppbmi`, `wtgain`, `smoken`, and `momage` with the reasons based on a hypothesized structure for the factors that underly birthweight:

  - Mother’s Pre-pregnancy BMI (ppbmi): Maternal BMI is a crucial indicator of maternal health and nutrition status, which significantly affect fetal growth. Both underweight and overweight pre-pregnancy BMIs are associated with adverse birth outcomes.
  
  - Baby’s length at birth (blength): Birth length and birth weight are directly related, as both are indicators of the baby's overall size and development. A longer baby is generally expected to weigh more.
  
  - Mother’s Age at Delivery (momage): Maternal age can influence birth outcomes, with very young and older mothers often facing higher risks of complications that can affect the baby's birth weight.
  
- Presence of Malformations (malform): Any congenital malformations could potentially impact the baby's growth and development, thereby affecting birth weight. 

  - Number of Cigarettes Smoked Per Day During Pregnancy (smoken): Smoking during pregnancy is a known risk factor for reduced fetal growth and low birth weight. The number of cigarettes smoked can have a dose-response relationship with birth weight.

  - Mother’s Weight Gain During Pregnancy (wtgain): Weight gain during pregnancy is directly related to fetal growth. Adequate weight gain is essential for a healthy birth weight, while both insufficient and excessive gains are risk factors for low and high birth weight, respectively.

```{r}
birthweight_model =
  lm(bwt ~ ppbmi + blength + momage + malform + smoken + wtgain, 
     data = birthweight_df)

summary(birthweight_model)
```

- Based on summary, most estimates are significant. The prediction seems pretty good.

### Then I will make a plot of model residuals against fitted values.

```{r}
birthweight_df |> 
  add_predictions(birthweight_model) |> 
  add_residuals(birthweight_model) |> 
  ggplot(
    aes( x = pred, y = resid)) + 
    geom_point(alpha = 0.5) +
  labs(
    title = "Model residuals against fitted values",
    x = "Fitted Values",
    y = "Residuals"
      )
```

-  The bulk of the data points form a dense cloud around the zero line of residuals, indicating that for many observations, the model’s predictions are close to the actual values. However, there's a visible spread of residuals as the fitted values increase, which might indicate heteroscedasticity—meaning the variability of the residuals is not constant across all levels of the independent variable(s). 
- Also, there are some outliers, particularly for higher fitted values, should be investigated further as they can have a significant influence on the regression model.

### Then I will compare my model to two others:

```{r}
cv_df =
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |> 
  mutate(
    my_model = map(.x = train, ~lm(bwt ~ ppbmi + blength + momage + malform + smoken + wtgain, data = birthweight_df)),
    main_model = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = birthweight_df)),
    interaction_model = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + blength * babysex + bhead * babysex + bhead * blength * babysex, data = birthweight_df))
         ) |> 
   mutate(
    rmse_my = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
    rmse_main = map2_dbl(main_model, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(interaction_model, test, ~rmse(model = .x, data = .y))
         )
```

- **my_model** is the model based on a hypothesized structure for the factors that underly birthweight I made previously.
- **main_model** is the model using length at birth and gestational age as predictors (main effects only).
- **interaction_model** is the model using head circumference, length, sex, and all interactions (including the three-way interaction) between these.

### Finally, I’ll plot the prediction error distribution for each candidate model.

```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse, color = model)) + 
    geom_violin() +
    labs(
      title = "Comparison of Cross-Validated Prediction Errors for Birth Weight Models"
        )
```

- From the violin plot, `my_model` has similar rmse performance of `main_model`. And `interaction_model` has the best performance because of lowest overall rmse value.
- Possible reason of bad performance of `my_model` can be extremely outlier in some variables influence rmse, cause we can clearly see some outliers in the graph of **Model residuals against fittted values** previously.